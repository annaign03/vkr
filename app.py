import streamlit as st
import numpy as np
import pandas as pd
from difflib import get_close_matches
import joblib
from transformers import AutoTokenizer, AutoModel
import torch
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import os
from catboost import CatBoostClassifier

torch.classes.__path__ = []

st.set_page_config(page_title="–ü–æ–¥–±–æ—Ä –≤–∞–∫–∞–Ω—Å–∏–π –∏ –æ—Ü–µ–Ω–∫–∞ —Ä–µ–∑—é–º–µ", layout="wide")


# === –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è ===
st.markdown("""
    <style>
    .stTextInput, .stSelectbox, .stNumberInput, .stRadio, .stTextArea {
        padding: 5px !important;
        border-radius: 8px;
    }
    .stButton > button {
        background-color: #4CAF50;
        color: white;
        border-radius: 10px;
        padding: 0.5em 2em;
        font-size: 1em;
    }
    </style>
""", unsafe_allow_html=True)
st.title("üìÑ –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—é–º–µ –∏ –ø–æ–¥–±–æ—Ä –≤–∞–∫–∞–Ω—Å–∏–π")

st.markdown("""
#### –≠—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∞—à–µ–≥–æ —Ä–µ–∑—é–º–µ –∏ –ø–æ–¥–±–æ—Ä–∞ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.

-  –ü–æ–ª—É—á–∏—Ç–µ –ø–æ–¥–±–æ—Ä–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π  
---
""")
col1, col2 = st.columns([1, 2])

with col1:
        st.subheader("üîß –í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö")
        birthday = st.number_input("–ì–æ–¥ —Ä–æ–∂–¥–µ–Ω–∏—è", min_value=1950, max_value=2024, value=1995)
        experience = st.number_input("–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã (–ª–µ—Ç)", min_value=0, value=2)
        salary = st.number_input("–ñ–µ–ª–∞–µ–º–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞ (‚ÇΩ)", value=60000)
        region_text = st.text_input("–†–µ–≥–∏–æ–Ω –ø—Ä–æ–∂–∏–≤–∞–Ω–∏—è")
        profession_text = st.text_input("–ñ–µ–ª–∞–µ–º–∞—è –ø—Ä–æ—Ñ–µ—Å—Å–∏—è", value='–ù–µ —É–∫–∞–∑–∞–Ω–æ')
        relocation = st.selectbox("–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –ø–µ—Ä–µ–µ–∑–¥—É", [1, 0], format_func=lambda x: "–î–∞" if x == 1 else "–ù–µ—Ç")
        retraining = st.selectbox("–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é", [1, 0], format_func=lambda x: "–î–∞" if x == 1 else "–ù–µ—Ç")
        business_trips = st.selectbox("–ö–æ–º–∞–Ω–¥–∏—Ä–æ–≤–∫–∏", [1, 0], format_func=lambda x: "–î–∞" if x == 1 else "–ù–µ—Ç")
        busy_type = st.multiselect("–¢–∏–ø –∑–∞–Ω—è—Ç–æ—Å—Ç–∏", options=['–ü–æ–ª–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å','–°–µ–∑–æ–Ω–Ω–∞—è','–°—Ç–∞–∂–∏—Ä–æ–≤–∫–∞','–£–¥–∞–ª–µ–Ω–Ω–∞—è','–ß–∞—Å—Ç–∏—á–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å'])
        schedule_type = st.multiselect("–ñ–µ–ª–∞–µ–º—ã–π –≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã", options=['–í–∞—Ö—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥','–ì–∏–±–∫–∏–π –≥—Ä–∞—Ñ–∏–∫','–ù–µ–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–±–æ—á–∏–π –≥—Ä–∞—Ñ–∏–∫','–ù–µ–ø–æ–ª–Ω—ã–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å','–ü–æ–ª–Ω—ã–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å','–°–º–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫'])
        skills = st.text_area("–ù–∞–≤—ã–∫–∏ (–≤ —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ)", value='–ù–µ —É–∫–∞–∑–∞–Ω–æ')

        submitted = st.button("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å")

with col2:
        if submitted:
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")

            df = pd.DataFrame(data = {'birthday':[birthday],
                               'business_trips':[business_trips],
                               'experience':[experience],
                               'relocation':[relocation],
                               'retraining_capability_x':[retraining],
                               'salary':[salary],
                               'schedule_type_1':[int('–í–∞—Ö—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥' in schedule_type)],
                               'schedule_type_2':[int('–ì–∏–±–∫–∏–π –≥—Ä–∞—Ñ–∏–∫' in schedule_type)],
                               'schedule_type_3':[int('–ù–µ–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–±–æ—á–∏–π –≥—Ä–∞—Ñ–∏–∫' in schedule_type)],
                               'schedule_type_4':[int('–ù–µ–ø–æ–ª–Ω—ã–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å' in schedule_type)],
                               'schedule_type_5':[int('–ü–æ–ª–Ω—ã–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å' in schedule_type)],
                               'schedule_type_6':[int('–°–º–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫' in schedule_type)],
                               'busy_type_–ü–æ–ª–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å':['–ü–æ–ª–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å' in busy_type],
                               'busy_type_–°–µ–∑–æ–Ω–Ω–∞—è':['–°–µ–∑–æ–Ω–Ω–∞—è' in busy_type],
                               'busy_type_–°—Ç–∞–∂–∏—Ä–æ–≤–∫–∞':['–°—Ç–∞–∂–∏—Ä–æ–≤–∫–∞' in busy_type],
                               'busy_type_–£–¥–∞–ª–µ–Ω–Ω–∞—è':['–£–¥–∞–ª–µ–Ω–Ω–∞—è' in busy_type],
                               'busy_type_–ß–∞—Å—Ç–∏—á–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å':['–ß–∞—Å—Ç–∏—á–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å' in busy_type],
                               'position_name':profession_text,
                               'skills':skills
                               })
            model_name = "DeepPavlov/rubert-base-cased"
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModel.from_pretrained(model_name)
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            model.to(device)

            # === 2Ô∏è‚É£ –û–ø—Ä–µ–¥–µ–ª—è–µ–º DataLoader –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –±–∞—Ç—á–∞—Ö ===
            class TextDataset(Dataset):
                def __init__(self, texts, tokenizer, max_length=512):
                    self.texts = [str(text)[:max_length] for text in texts]  # –û–±—Ä–µ–∑–∞–µ–º –¥–æ 512 —Å–∏–º–≤–æ–ª–æ–≤
                    self.tokenizer = tokenizer
                
                def __len__(self):
                    return len(self.texts)
                
                def __getitem__(self, idx):
                    return self.texts[idx]
            # === 3Ô∏è‚É£ –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ ===
            text_features = [
                'position_name', 
                'skills'
            ]
            # === 4Ô∏è‚É£ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤ –±–∞—Ç—á–∞—Ö ===
            batch_size = 32
            for feature in text_features: 
                dataset = TextDataset(df[feature].fillna("–ù–µ —É–∫–∞–∑–∞–Ω–æ").tolist(), tokenizer)
                dataloader = DataLoader(dataset, batch_size=batch_size)
                embeddings = []
                model.eval()
                with torch.no_grad():
                    for batch in tqdm(dataloader, total=len(dataloader)):
                        inputs = tokenizer(batch, padding=True, truncation=True, max_length=512, return_tensors="pt").to(device)
                        outputs = model(**inputs)
                        embeddings.extend(outputs.last_hidden_state.mean(dim=1).cpu().numpy())
                bert_df = pd.DataFrame(embeddings, columns=[f"{feature}_emb_{i}" for i in range(768)])
                df = pd.concat([df.reset_index(drop=True), bert_df.reset_index(drop=True)], axis=1)
            scaler = joblib.load('scaler.pkl')
            numerical_features = ['birthday', 'experience', 'salary']
            df[numerical_features] = scaler.transform(df[numerical_features])
            pca = joblib.load('pca_model.pkl')
            embedding_columns = [col for col in df.columns if 'skills_emb' in col or 'position_name_emb' in col]
            X1 = df[embedding_columns]
            X1_reduced = pca.transform(X1)
            X1_reduced_df = pd.DataFrame(X1_reduced, columns=[f'resume_emb_{i}' for i in range(300)])
            df = pd.concat([df.drop(columns=embedding_columns), X1_reduced_df], axis=1)
            df = df.drop(columns=['skills','position_name'])
            model = CatBoostClassifier()
            model.load_model("resume_quality_model.cbm")
            resume_cols = [col for col in df.columns if col.startswith('resume_emb_')]
            resume_additional = [
                'business_trips', 'experience',
                'relocation', 'retraining_capability_x', 'salary'
            ] + [col for col in df.columns if 'schedule_type' in col or 'busy_type' in col]
            resume_features = resume_cols + resume_additional
            df1 = list(df[resume_features].values)
            X_new = np.array(df1).reshape(1, -1)
            prob_success = model.predict_proba(X_new)[0, 1]
            df.to_csv('test.csv', sep=';', encoding='cp1251')
            st.success(f"–û—Ü–µ–Ω–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ —Ä–µ–∑—é–º–µ: {round(prob_success*100,1)}%")
            st.markdown("### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏:")
            # === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
            df1 = pd.read_csv('for_site.csv')
            df1 = df1.drop_duplicates(subset='id_vacancy')
            # –ü–æ–≤—Ç–æ—Ä–∏–º —Ç—É –∂–µ –ª–æ–≥–∏–∫—É –≤—ã–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            resume_cols = [col for col in df1.columns if col.startswith('resume_emb_')]
            vacancy_cols = [col for col in df1.columns if col.startswith('vacancy_emb_')]

            resume_additional = ['birthday', 'business_trips', 'experience', 'relocation', 'retraining_capability_x', 'salary'] + \
                                [col for col in df1.columns if 'schedule_type' in col or 'busy_type' in col]

            vacancy_additional = ['accommodation_capability', 'base_salary_max', 'base_salary_min', 'disabled', 'dms',
                                'experience_requirements', 'large_families', 'single_parent',
                                'vouchers_health_institutions', 'work_places', 'workers_with_disabled_children'] + \
                                [col for col in df1.columns if 'education_type' in col or 'employment_type' in col or
                                'inner_info' in col or 'source_' in col or 'education_requirements' in col]

            resume_features = resume_cols + resume_additional
            vacancy_features = vacancy_cols + vacancy_additional

            X_resume = df[resume_features].astype(np.float32).values
            X_vacancy = df1[vacancy_features].astype(np.float32).values

            # === –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ===
            class ResumeVacancyModel(torch.nn.Module):
                def __init__(self, resume_dim, vacancy_dim):
                    super().__init__()
                    self.fc = torch.nn.Sequential(
                        torch.nn.Linear(resume_dim + vacancy_dim, 256),
                        torch.nn.ReLU(),
                        torch.nn.Linear(256, 128),
                        torch.nn.ReLU(),
                        torch.nn.Linear(128, 64),
                        torch.nn.ReLU(),
                        torch.nn.Linear(64, 1),
                        torch.nn.Sigmoid()
                    )

                def forward(self, resume_input, vacancy_input):
                    x = torch.cat((resume_input, vacancy_input), dim=1)
                    return self.fc(x).squeeze()

            # === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ===
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            model = ResumeVacancyModel(X_resume.shape[1], X_vacancy.shape[1])
            model.load_state_dict(torch.load("resume_vacancy_model2.pth", map_location=device))
            model.to(device)
            model.eval()

            # === –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ ===
            def recommend_vacancies(resume_vector, vacancy_matrix, model, top_n=10):
                resume_batch = np.repeat(resume_vector[np.newaxis, :], vacancy_matrix.shape[0], axis=0)
                with torch.no_grad():
                    inputs_r = torch.tensor(resume_batch, dtype=torch.float32).to(device)
                    inputs_v = torch.tensor(vacancy_matrix, dtype=torch.float32).to(device)
                    scores = model(inputs_r, inputs_v).cpu().numpy()
                top_indices = np.argsort(scores)[::-1][:top_n]
                return top_indices, scores[top_indices]

            # === –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ===
            resume_example = X_resume[0]  # –∏–ª–∏ –∑–∞–º–µ–Ω–∏ –Ω–∞ —Å–≤–æ—ë —Ä–µ–∑—é–º–µ
            top_idxs, top_scores = recommend_vacancies(resume_example, X_vacancy, model)

            # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            recommended_vacancies = df1.iloc[top_idxs]
            vac = recommended_vacancies[['id_vacancy']]
            df2 = pd.read_csv('for_rec.csv')
            df2 = df2.drop_duplicates(subset='id_vacancy')
            res = df2[df2.id_vacancy.isin(vac.id_vacancy)][['title','base_salary_min','base_salary_max','job_benefits_other_benefits','job_location_address','requirements_qualifications','responsibilities','additional_info']]
            for index, row in res.iterrows():
                with st.container():
                    st.markdown(f"""
                    <div style="border: 1px solid #444; border-radius: 10px; padding: 15px; margin-bottom: 15px; background-color: #1e1e1e;">
                        <h4 style="color: #4CAF50;">{row['title']}</h4>
                        <p><strong>–ê–¥—Ä–µ—Å:</strong> {row['job_location_address']}</p>
                        <p><strong>–ó–∞—Ä–ø–ª–∞—Ç–∞:</strong> {row['base_salary_min']} ‚Äì {row['base_salary_max']} ‚ÇΩ</p>
                        <p><strong>–¢—Ä–µ–±—É–µ–º–∞—è –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è:</strong> {row['requirements_qualifications']}</p>
                        <p><strong>–î–æ–ª–∂–Ω–æ—Å—Ç–Ω—ã–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏:</strong> {row['responsibilities']}</p>
                        <p><strong>–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:</strong> {row['additional_info']}</p>
                        <p><strong>–ë–æ–Ω—É—Å—ã/–ª—å–≥–æ—Ç—ã:</strong> {row['job_benefits_other_benefits']}</p>
                    </div>
                    """, unsafe_allow_html=True)


            # for i, (title, salary_min, salary_max) in enumerate([
            #     ("–£—á–∏—Ç–µ–ª—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞", 50000, 70000),
            #     ("–ú–µ—Ç–æ–¥–∏—Å—Ç –≤ –ª–∏—Ü–µ–π", 60000, 85000),
            #     ("–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏", 55000, 75000)
            # ], 1):
            #     link = f"/vacancy?id={i}"
            #     st.markdown(f"{i}. [{title} ‚Äî {salary_min}‚Äì{salary_max}‚ÇΩ](#{link})")

